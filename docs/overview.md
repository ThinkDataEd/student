#Introduction to Data Science: Overview & Philosophy

##**Course Overview**

###**Goals**

Introduction to Data Science (IDS) is designed to introduce students to the exciting opportunities available
at the intersection of data analysis, computing, and mathematics through hands-on activities. Data are
everywhere, and this curriculum will help prepare students to live in a world of data. The curriculum
focuses on practical applications of data analysis to give students concrete and applicable skills. Instead
of using small, tailored, curated data sets as in a traditional statistics curriculum, this curriculum engages
students with a wider world of data that fall into the "Big Data" paradigm and are relevant to students'
lives. In contrast to the traditional formula-based approach, in IDS, statistical inference is taught
algorithmically, using modern randomization and simulation techniques. Students will learn to find and
communicate meaning in data, and to think critically about arguments based on data.

This curriculum was developed in partnership with the Los Angeles Unified School District for a culturally,
linguistically, and socially diverse group of students. Upon first publication of the IDS curriculum in 2015,
the district-wide student ethnicities included .3% American Indian, 3.7% Asian, .4% Pacific Islander, 2.3%
Filipino, 73.0% Latino, 10.9% African American, 8.8% White, and .6% other/multiple responses. Over
38% of students were English-language learners – most of whom spoke Spanish as their primary
language – and 74% of students qualified for free or reduced lunches.

###**Standards**

The standards used for the IDS curriculum are based on the High School Probability and Statistics
Mathematics Common Core State Standards **(CCSS-M)**, and include the Standards for Mathematical
Practice **(SMP)**. Specific standards are delineated in the scope and sequence section. The Computer
Science Teacher’s Association **(CSTA)** K-12 Computer Science Standards were also consulted and
incorporated. Applied Computational Thinking Standards **(ACT)** delineate the application of Data Science
concepts using technology.

###**Hardware**

An ideal laboratory environment has a 1:1 computer to student ratio. The computers can be either Apple,
PC, or Chromebook, depending upon availability. Internet access is required for the use of RStudio on an
external server. The IDS instructor must have access to a computer and a projector for daily use.

###**Software**

Each computer in the classroom should have a modern, updated web browser installed (such as Firefox
or Google Chrome). This will allow students to access RStudio from an external server, and to perform
searches and make use of a variety of websites and Internet tools. RStudio is available at
[https://tools.idsucla.org](https://tools.idsucla.org "https://tools.idsucla.org"). The IDS team will provide the remainder of the software used in the IDS
curriculum, available at [https://tools.idsucla.org](https://tools.idsucla.org "https://tools.idsucla.org")
This software includes the [IDS UCLA app](download/app.md), which is deployed for [Android](https://play.google.com/store/apps/details?id=edu.ucla.oit.idsucla) and [iOS](https://itunes.apple.com/us/app/ids-ucla/id1422869521) smartphones and
tablets, as well as through the web browser on a desktop or laptop computer. The app allows students to
collect the Participatory Sensing data that is a motivational foundation for the course. In addition to the
app, students will use the IDS software to access and manipulate their Participatory Sensing data, and to
author their own campaigns.

All computer-based assignments will be completed in class to avoid the assumption that students have
access to computers at home. However, if a student misses a lab assignment, they will need to make it
up on their own time. All the software required for the curriculum is available via the Internet, so students
can complete the assignment on any Internet-enabled computer (e.g., at the school or public library).

###**Prerequisites**

It is recommended that students successfully complete a first-year Algebra course prior to taking IDS.
With this background, the curriculum provides a rigorous but accessible introduction to data science and
statistics. No previous statistics or computer science courses are required to take this course.

###**The Instructional Philosophy of Introduction to Data Science**

IDS uses a project-based learning approach to instruction. Finkle and Torp (1955) define Project-Based
Learning (PBL) as a curriculum development and instructional system that simultaneously develops both
problem-solving strategies and disciplinary knowledge bases and skills by placing students in the active
role of problem solvers confronted with an ill-structured problem that mirrors real-world problems. PBL,
therefore, is a model for teaching and learning that focuses on the main concepts and principles of a
discipline, involves students in problem-solving investigations and other meaningful tasks, allows students
to construct their own knowledge through inquiry, and culminates in a project.

Because IDS is a mathematical science, the BSCS 5-E Instructional Model provides a planned sequence
of instruction that places students at the center of their learning experiences. This model encourages
students to explore, create their own meaning of concepts, and relate their understanding to other
concepts. The units in IDS contain lessons that, together, fit the 5-E Instructional Model:

| **Stage of Inquiry in an Inquiry-Based Science Program** | **Possible Student Behavior** | **Possible Teacher Strategy** |
|------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| **Engage** | Asks questions such as, Why did this happen? What do I already know about this? What can I find out about this? How can I solve this problem? Shows interest in the topic. | Creates interest. Generates curiosity. Raises questions and problems. Elicits responses that uncover student knowledge about the concept/topic. |
| **Explore** | Thinks creatively within the limits of the activity. Tests predictions and hypotheses. Forms new predictions and hypotheses. Tries alternatives to solve a problem and discusses them with others. Records observations and ideas. Suspends judgment. Tests ideas. | Encourages students to work together without direct instruction from the teacher. Observes and listens to students as they interact. Asks probing questions to redirect students' investigations when necessary. Provides time for students to puzzle through problems. Acts as a consultant for students. |
| **Explain** | Explains their thinking, ideas, and possible solutions or answers to other students. Listens critically to other students' explanations. Questions other students' explanations. Listens to and tries to comprehend explanations offered by the teacher. Refers to previous activities. Uses recorded data in explanations. | Encourages students to explain concepts and definitions in their own words. Asks for justification (evidence) and clarification from students. Formally provides definitions, explanations, and new vocabulary. Uses students' previous experiences as the basis for explaining concepts. |
| **Elaborate** | Applies scientific concepts, labels, definitions, explanations, and skills in new, but similar situations. Uses previous information to ask questions, propose solutions, make decisions, and design experiments. Draws reasonable conclusions from evidence. Records observations and explanations. | Expects students to use vocabulary, definitions, and explanations provided previously in new context. Encourages students to apply the concepts and skills in new situations. Reminds students of alternative explanations. Refers students to alternative explanations. |
| **Evaluate** | Checks for understanding among peers. Answers open-ended questions by using observations, evidence, and previously accepted explanations. Demonstrates an understanding or knowledge of the concept or skill. Evaluates his or her own progress and knowledge. Asks related questions that would encourage future investigations. | Refers students to existing data and evidence and asks, What do you know? Why do you think...? Observes students as they apply new concepts and skills. Assesses students' knowledge and/or skills. Looks for evidence that students have changed their thinking. Allows students to assess their learning and group process skills. Asks open-ended questions such as, Why do you think...? What evidence do you have? What do you know about the problem? How would you answer the question? |

IDS is designed to develop students' computational and statistical thinking skills. Computationally,
students will learn to write code to enhance analyses of data, to break large problems into smaller pieces,
and to understand and employ algorithms to solve problems. Statistical thinking skills include developing
a data "habit of mind" in which one learns to seek data to answer questions or support (or undermine)
claims; thinking critically about the ability of particular data to support claims; learning to interpret
analyses of data; and learning to communicate findings.

IDS employs Participatory Sensing to give students control of the data collection process, and to enable
them to collect data about things that are important to them. The curriculum is organized around a series
of Participatory Sensing "campaigns" in which students engage in all stages of the statistical process,
which we call the Data Cycle: asking questions, examining and collecting data, analyzing data,
interpreting data and, if necessary, beginning again. As students progress, they engage in the Data Cycle
in a deeper way. Initially, analysis and interpretation is purely descriptive. Later, randomization-based
algorithms and simulations are used to develop notions of inference and to make students more critical of
the data collection process. By engaging in the Data Cycle repeatedly in different contexts - some of
which include the students' own designs - students will learn to think like data scientists.

###**Student Team Collaboration**

Many of the activities in the IDS curriculum are based on students collaborating with each other. Activities
may call on pairs or teams of students. **<u>It is imperative that teams and team roles be established as
close to the beginning of the course as possible.</u>** Expectations about teamwork should be introduced
as soon as teams are formed. The ideal team comprises four students. The Teacher Resources section
provides a list of instructional strategies and a description of team roles to use for effective student team
collaboration. If student teams are unfamiliar with these instructional strategies, it is important for the
instructor to take the time to model each strategy.

###**Classroom Discussions**
Because this is an inquiry-based curriculum, classroom discussion will be especially important. It is
important to set classroom discussion norms from the beginning of the course. All students should be
encouraged to contribute to the classroom discussion, and the learning environment should be as non-judgmental
and as open as possible. Instead of one right answer, most questions in this class have many
right answers. In fact, even yes/no questions could have two right answers, both with valid supporting
evidence. Teachers should create an environment to help students hold each other accountable so that
all voices are heard, meaning that if there are a few students who tend to share a lot, invite them to
encourage their peers so other voices can be heard. If there are students who tend to avoid contributing
to the class discussion, encourage them to share so that their voices are heard.

###**Assignments & Homework**
As much as possible, IDS work will take place in the classroom. Lessons are designed for a 50-60 minute
class period. Classes on block schedule will need to complete two lessons; however, it is up to the
teacher to decide where to stop in each lesson. There will be open-ended assignments that are sent
home. Assignments that require the computer will be completed in class, to avoid the assumption that
students have access to computers at home. The exception to this is if a student misses lab time, in
which case they will need to find a time to complete the assignment outside of class. As discussed in the
software section above, they can use an Internet-enabled computer to do their make-up work.

IDS assignments will not be drill-based. Instead, they will follow the inquiry-based instructional model.
Again, most questions will not have one right answer. Instead, students will learn to support their claims
with evidence and to participate in data-based discussions. Newspaper or other periodical or digital
articles are available via links in the lessons. If desired, articles may be downloaded and printed.
On average, students will complete a lab assignment in RStudio approximately once per week. It will be
at the discretion of the teacher whether or not to collect lab assignments. Calculators should be available
every day for students to use.

Every day, students will be expected to bring their Data Science (DS) journal, a notebook where they
record their notes, work on small assignments, and sketch plots. Teachers may choose to check DS
journals and other assignments in the curriculum for credit.
End of Unit Projects, oral presentations, and Practicums are designed as application exercises. Scoring
guides are provided as an aid for student performance expectations. It will be up to the teacher to score
or attach a grade to these assignments.

##**Overview of Instructional Topics**
The purpose of IDS is to introduce students to dynamic data analysis. The four major components of this
curriculum are based on the conceptual categories called upon by the Common Core State Standards
High School - Statistics and Probability:

<ul style="list-style-type:none">
	<b><li>I. Interpreting Categorical and Quantitative Data</li></b>
    <b><li>II. Making Inferences and Justifying Conclusions</li></b>
    <b><li>III. Conditional Probability and the Rules of Probability</li></b>
    <b><li>IV. Using Probability to Make Decisions</li></b>
</ul>

IDS will emphasize the use of statistics and computation as tools for creative work, and as a means of
telling stories with data. Seen in this way, its content will also prepare students to "read" and think
critically about existing data stories. Ultimately, this course will be about how we discern good stories
from bad through a practice that involves compiling evidence from one or more sources, and which often
requires hands-on examination of one or more data sets.

IDS will develop the tools, techniques, and principles for reasoning about the world with data. It will
present a process that is iterative and authentically inquiry-based, comparing multiple "views" of one or
more data sets. Inevitably, these views are the result of some kind of computation, producing numerical
summaries or graphical displays. Their interpretation relies on a special kind of computation known as
simulation to describe the uncertainty in each view. This kind of reasoning is exploratory and
investigatory, sometimes framed as hypothesis evaluation, and sometimes as hypothesis generation.

###**Interpreting Categorical and Quantitative Data**

A handful of data interpretations are standard. Some, including summaries of shape, center, and spread
of one or more variables in a data set - as well as graphical displays like histograms and scatterplots - are
standard in the sense that they provide interpretable information in a number of research contexts. They
are portable from one set of data to the next, and the rules for their use are simple. And yet, our
interpretation of data is rarely “standard.” Data have no natural look - even a spreadsheet or a table of
numbers embeds within it a certain representational strategy. We construct multiple views of data in an
attempt to uncover stories about the world.

In addition to numerical data, this course will consider time, location, text, and image as data types, and
will examine views that uncover patterns or stories. Throughout the course, simulation will be used to
calibrate our interpretation of a view, or of a numerical or graphical summary, so that we understand what
“story-less” data (i.e., pure noise, no association) look like.

In addition to summaries and simple graphics, students will engage in a modeling practice aligned with
the CCSS mathematical practices in order to learn how statistical analyses can explain and describe real-world
phenomena. Students will practice fitting and evaluating standard mathematical and statistical
models, such as the least-squares regression line. Modeling comes into play when students are asked to
design and implement probabilistic simulations in order to test and compare hypothetical chance
processes to real-world data.

###**Making Inferences and Justifying Conclusions**

Data are becoming increasingly plentiful, supported by a host of new "publication" techniques or services.
Post-Web 2.0, data are interoperable, flowing out of one service and into another, helping us easily build
a detailed data version of many phenomena in the world. Reasoning with data, then, starts with the
sources and the mechanics of this flow. Which sources do we trust? How do data from different
organizations compare? What stories have been told previously with these data, and by whom?

This course answers these questions, in part, by using the tools and techniques already mentioned. The
ability to read and critique published stories and visualizations are additions to these tools and
techniques. Finally, as an act of comparison, students should also be able to formulate questions, identify
existing data sets, and evaluate how the new stories stack up against the old. To support this cycle of
inquiry, students will examine the basic publication mechanisms for data and develop a set of questions
to ask of any data source - computation meets critical thinking. In some cases, data will exhibit special
structures that can be used to aid in inference. The simulation techniques for calibrating different views of
a data set take on new life when some form of random process was followed to generate the data. Polls,
for example, rely on random samples of the population, and clinical trials randomly assign patients to
treatment and control groups. A simulation strategy that repeats these random mechanisms can be used
to assess uncertainty in the data, assigning a margin of error to poll results, or identifying new drugs that
have a "significant" effect on some health outcome.

In many cases, data will not possess this kind of special origin story. A census, for example, is meant to
be a complete enumeration of a population, and we can reason in a very direct way from the data. In
other cases, no formal principle was applied, perhaps being a sample "of convenience." The techniques
for telling stories from these kinds of data will also rely on a mix of simulation and subsetting.
Finally, this course will introduce Participatory Sensing as a technique for collecting data. The idea of a
data collection campaign will be introduced as a means of formalizing a question to be addressed with
data. Campaigns will be informed by research and data analysis, and will build on, augment, or challenge
existing sources. The "culture" behind the existing sources and the summaries or views they promote will
be part of the classroom discussions.

It is worth noting that everything described so far depends on computation, using a piece of statistical
software on a computer. Students will be taught simple programming tools for accessing data, creating
views or fitting models, and then assessing their importance via simulation. Computation becomes a
medium through which students learn about data. The more expressive the language, the more elaborate
the stories we can tell.

###**Probability**

Since simulation is our main tool for reasoning with data, interpreting the output of simulations requires
understanding some basic rules of probability. First and foremost, this course will discuss the ways in
which a computer can generate random phenomena (e.g., How does a computer toss a coin?). Simple
probability calculations will be used to describe what we expect to see from random phenomena, then
students will compare their results to simulations. The point is to both rehearse these basic calculations
and to make a formal tie between simulation and theory in simple cases.

In that vein, this course will motivate the relationship between frequency and probability. Students will
essentially be simulating independent trials and creating summaries of those simulations. In turn, they
should understand that the frequency with which an event occurs in a series of independent simulations
tends to the probability for that event as the number of simulations gets large (the Law of Large Numbers,
a topic that is often taught in introductory statistics courses).

From here, students will simulate a variety of random processes to aid in formal statistical inference when
some random mechanism was applied as part of the data design. In short, probability becomes a ruler of
sorts for assessing the importance of any story we might tell. In this approach to probability, a
combination of direct mathematical calculation and computer simulations will be used in order to give
students a deep sense of the underlying statistical concepts.

##**Topic Outline**

This outline describes only the scope of the course; the sequence is described in each unit.

###**I. Interpreting Data**

A. Types of data

B. Numerical and graphical summaries

1. Measures of center and spread, boxplots

2. Bar plots

3. Histograms

4. Scatterplots

5. Graphical summaries of multivariate data

C. Simulation and visual inference

1. Side-by-side bar plots and association

2. Scatterplots

D. Models

1. Linear models

2. k-means

3. Smoothing

4. Learning and tree-based models

###**II. Making Inferences and Justifying Conclusions**

A. Aggregating data

1. Identification of sources

2. Mechanics of Web 2.0

3. Comparison of sources

B. Data with special structures

1. Random sampling

2. Random assignment and A/B testing

3. Simulation-based inference

C. Participatory Sensing

1. Designing a campaign

2. Participation as a data collection strategy

###**III. Probability**

A. Computers and randomness

1. Web services

2. Pseudo-random numbers (optional)

B. Frequency and probability

C. Probability calculations

###**IV. Algebra in RStudio**

1. Vectors

2. Algorithms

3. Functions

4. Evaluating and fitting models to data

5. Graphical representations of multivariate data

6. Numerical summaries of distributions and interpreting in context

